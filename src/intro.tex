
\chapter{Introduction}

%Code size is a critical issue whenever the program size becomes too large for the available resources.
Program size is a critical issue whenever it becomes excessively large relative to given constraints such as the addressable memory space, storage size, download bandwidth, etc.
As programs gain new features over time, continuously growing in complexity, program size can often become a critical issue for anything ranging from the context of tiny embedded devices up to extremely large programs in servers.
As a result, reducing the code size is essential~\cite{schultz03,varma04,sehgal12,keoh14,auler17} and compilation techniques must be developed and tuned primarily for optimising binary size.

%For example, mobile and embedded systems must often run on inexpensive and resource-constrained devices , with limited memory, storage, and CPU caches.
%This ranges from programs for small 
%In recent years, the market for mobile and embedded systems has been rapidly growing.
%These systems must often run on inexpensive and resource-constrained devices, with limited memory, storage, CPU caches. %and their applications are designed with different goals compared to traditional computing systems.
%Applications for these systems are designed and built with different goals compared to traditional computing systems since their binaries must fit in a limited memory size.
%One way to deal with limited memory is to develop compilation techniques which generate small binaries.
%Hence, compilation techniques must be primarily focused on optimising for binary size.
%Compilation techniques can be used to 
%It is therefore important that program these system are optimised for binary size.

%Furthermore, the rise of the Internet of Things (IoT) depends heavily on tiny and efficient devices.
%Some of these devices can have as little as only a few kilobytes of
%memory~\cite{yelamarthi17,plaza18}.
%At the same time, low-end devices have been playing an important role in driving
%innovation in developing countries~\cite{hart02,etzo10}.


Embedded systems are becoming pervasive as well as increasingly complex, with their application binaries often reaching several megabytes in size, turning memory size into a limiting factor~\cite{plaza18}.
Just adding more memory is not always a viable option.
Highly integrated systems-on-chip are common in this market and their memories typically occupy the largest fraction of the chip area, contributing to most of the overall cost.
Even small increases in memory area translate directly to equivalent increases in cost, which lead to enormous levels of lost profit at large scales~\cite{edler10}.
In addition to cost, embedded systems are also often limited by other factors such as weight, energy consumption, etc.~\cite{tiggeler00,edwards20}.

%Modern mobile application binaries are bulky for many reasons: software and its dependencies, fast-paced addition of new features, high-level language constructs, and statically linked platform libraries.
Modern mobile applications tend to have large binaries that need to support as many devices as possible, including low-end devices with limited resources~\cite{hart02,etzo10}.
Furthermore, Apple App Store imposes a limit when downloading an application over the mobile broadband.
Applications larger than this limit must be downloaded only over the Wi-Fi.
These restrictions on the size of the application may significantly impact revenues for critical businesses.
Chabbi~et~al.~\cite{chabbi21} have shown that certain large applications may have over 90\%
of its total size being taken by their binary code, where the remaining size is due to media and resources.
For these applications, reducing the application's binary size becomes of utmost importance for their businesses.
%For these systems, reducing the binary size helps to improve the end-user experience but it is also critical for conforming with vendor's download-size limitations.
%Moreover, data consumption over wireless carriers can be either limited or expensive.
%As a result, there is an increasing focus on the development of programs tailored for these low-end devices with limited memory sizes~\cite{androidGo,hahm16}.


Beyond just mobile and embedded systems, address space also limits how large programs can become.
Upgrading computers at scale is a challenging and costly process even for large datacenters~\cite{yan16,neamtiu11}.
As a result, outdated 32-bit machines have an addressable memory space limited to less than 4.5~GB, setting a limit on program size.
This limitation is even more noticeable on smaller machines with shorter word widths.
In such constrained scenarios, reducing the application footprint is essential~\cite{schultz03,varma04,sehgal12,keoh14,auler17}.
This is traditionally achieved by focusing on reducing the code size, either when designing the source code or by tuning the compiler to optimise for size~\cite{fisher05,sehgal12,hennessy17,rocha19}.
%Unfortunately, production compilers offer little help beyond dead-code elimination or merging identical functions~\cite{tallam10,kwan12,livska14}.
%Developers might have more luck just removing functionality from their libraries~\cite{keoh14} or hand-optimizing their code~\cite{weaver09}.
%Despite the importance of keeping code size small, compilers still make little effort to reduce it, except for these classical optimisations, their efforts are limited to disabling performance optimisations which increase size.
Despite the importance of keeping code size small, production compilers offer little help beyond a few classical optimisations~\cite{cocke70,briggs97,debray00}.
Because of that, to avoid the expensive costs of extra storage and memory, the developers of these systems have to manually find ways to shrink their code, which is also costly and undesirable~\cite{keoh14,weaver09}.

Code-size optimisations work by replacing a piece of code with another that is semantically equivalent but uses fewer or smaller instructions, sometimes combining and reusing equivalent pieces of code.
Classical optimisations that are effective in reducing code size include the elimination of redundant, unreachable, and dead code, as well as certain kinds of strength reduction~\cite{cocke70,briggs97,debray00}.
Although initially motivated by performance, these classical optimisations achieve better performance by focusing on code-size reduction.

One important optimisation capable of reducing code size is function merging.
In its simplest form, function merging reduces replicated code by combining multiple identical functions into a single one~\cite{llvm-fm,livska14}.
This optimisation is found in linkers, by the name of \textit{identical code folding}~(ICF), where text-identical functions at the bit level are merged~\cite{tallam10,kwan12,msvc-icf}.
However, such solutions are platform-specific and need to be adapted for each object code format and hardware architecture.
Alternatively, compilers also provide a similar optimisation for merging identical functions at their mid-level intermediate representation (IR) and hence is agnostic to the target hardware~\cite{llvm-fm,livska14}.
Unfortunately, these optimisations can only merge fully identical functions with at most type mismatches that can be losslessly cast to the same format.

More advanced approaches can identify similar, but not necessarily identical, functions and replace them with a single function that combines the functionality of the original functions while eliminating redundant code.
At a high level, the way this works is that code specific to only one input function is added to the merged function but made conditional to a function identifier, while code found in both input functions is added only once and executed regardless of the function identifier.
%The work presented by von Koch~et~al.~\cite{edler14} proposed a merging strategy that exploits the isomorphism in the control-flow graphs (CFG) of the functions being merged.
%These functions can only differ between corresponding instructions, specifically, in their opcodes or the number and types of the input operands.
%However, they must have identical CFGs and function types.

%Although a simple and intuitive concept, it is crucial for making high-level abstractions usable, when they introduce duplicate code~\cite{tallam10,kwan12}.
%For example, some C++ ABIs may end up creating multiple identical constructors and destructors of a class to use in different contexts~\cite{kwan12} and C++ templates replicate code for different specialisations~\cite{tallam10,livska14}.
%More advanced approaches~\cite{edler14} have extended this idea into merging non-identical functions by leveraging structural similarity.
%Functions with identical control-flow graphs (CFGs) and only small differences within corresponding basic blocks are merged into a single function that maintains the semantics of the original functions.
%This is particularly important for handling specialised template functions with small differences in their compiled form.

%This includes optimisations that range from local to inter-procedural, such as:
%peephole optimisations that perform code simplification~\cite{tanenbaum82};
%elimination of unreachable or dead code~\cite{muchnick98};
%optimisations that reduce redundancies such as common-subexpression elimination and value numbering~\cite{cocke70,briggs97};
%procedural abstraction and function merging~\cite{loki04,edler10,rocha19}.

%Similar functions can arise for several reasons
%Generative programming~\cite{czarnecki99,draheim04}.
%Copy-and-paste programming~\cite{kim04,jablonski10,ahmed15}.

% Function merging reduces replicated code by combining multiple identical functions into a single one~\cite{llvm-fm,livska14}. 
% Although a simple and intuitive concept, it is crucial for making high-level
% abstractions usable, when they introduce duplicate code~\cite{tallam10,kwan12}.
% For example, some C++ ABIs may end up creating multiple identical constructors
% and destructors of a class to use in different contexts~\cite{kwan12} and C++
% templates replicate code for different specialisations~\cite{tallam10,livska14}.
% More advanced approaches~\cite{edler14} have extended this idea into
% merging non-identical functions by leveraging structural similarity. Functions
% with identical control-flow graphs (CFGs) and only small differences within
% corresponding basic blocks are merged into a single function that maintains
% the semantics of the original functions. This is particularly important for
% handling specialized template functions with small differences in their
% compiled form.

Unfortunately, existing approaches fail  to produce any noticeable code size reduction.
In this work, we introduce a novel way to merge functions that overcomes major limitations of existing techniques.
Our insight is that the weak results of existing function merging implementations are not due to the lack of duplicate code but due to the rigid, overly restrictive algorithms they use to find duplicates.

% While an improvement, even the state-of-the-art often usually fails to produce any
% noticeable code size reduction.
% In this paper, we introduce a novel way to merge
% functions that overcomes the major limitations of the state-of-the-art. Our
% insight is that the weak results of existing function merging implementations
% are not due to the lack of duplicate code but due to the rigid, overly restrictive
% algorithms they use to find duplicates.

Our approach is based upon the concept of sequence alignment, developed in bioinformatics for identifying functional or evolutionary relationships between different DNA or RNA sequences.
Similarly, we use sequence alignment to find areas of functional similarity in arbitrary function pairs.
Aligned segments with equivalent code are merged.
The remaining segments where the two functions differ are added to the new function too but have their code guarded by a function identifier.
This approach leads to significant code size reduction.
%more than three times better than the state-of-the-art can achieve.

Attempting to merge all pairs of functions is prohibitively expensive even for medium sized programs, considering the quadratic nature of sequence alignment.
To counter this, our technique is integrated with a ranking-based exploration mechanism that efficiently focuses the search to the most
promising pairs of functions. %\todo{whats interesting about this ranking?}.
As a result, we achieve our code size savings while introducing little compilation-time
overhead.

Compared to identical function merging, we introduce extra code to be executed,
namely the code that chooses between dissimilar sequences in merged functions.
A naive implementation could easily hurt performance, e.g by merging two hot functions
with only few similarities. It is also possible to avoid performance degradation by incorporating
profiling information in the decision-making, enabling the compiler to avoid merging functions that contain hot code, as shown in Chapter~\ref{chp:cgo19}.
%identify blocks of hot code and effectively minimise the overhead in this portion of the code.
%disable code size optimisations for them. 

\section{Contribution}

In this thesis, we make the following contributions:
\begin{itemize}
  \item 
  We present a novel function merging optimisation for code size reduction.
  Our technique is the first that allows merging arbitrary functions, including functions with different signatures and control flow graphs.
  The proposed optimisation uses sequence alignment to identify code similarity and guide the merging operation.
  It also merges parameters based on their usage, minimising the number of parameters and operand selection, and handles different returning using a union-like approach.
  The goal is to maximise the amount of merged code while minimising the overhead required to handle the differences.
  
  \item
  Since our technique is able to merge any pair of functions, it is necessary to identify which pairs of functions are the most profitable to merge.
  We introduce a novel ranking mechanism for focusing our optimisation on function pairs that are more likely to be profitably merged.
  The proposed mechanism first pre-computes fingerprints summarising each function and later use them to rank function candidates based on the fingerprint similarity.
  For each function, merging will be only attempted for the top ranked candidates, significantly reducing compilation overhead while still significantly improving on code size reduction.

  %\item
  %Our function merging by sequence alignment technique is able to reduce code size by up to 25\% on Intel and 30\% on ARM, significantly outperforming the state-of-the-art, while introducing minimal compile-time and negligible run-time overheads.

  \item
  We present an improved code generator for the function merging transformation, effectively merging functions in the SSA form, including phi-nodes.
  This removes the need to perform register demotion prior to function merging, resulting in smaller functions being merged. 
  This approach results in better merged functions for not relying in later reversing the effects of register demotion.
  Merging smaller functions also significantly reduces compilation overhead, due to the quadratic nature of sequence alignment.

  \item
  The code generator also includes a novel phi-node coalescing optimisation tailored for function merging, reducing the total number of phi-nodes and easing the pressure on registers.
  Phi-node coalescing is able to reduce the number of phi-nodes and selection, producing smaller merged functions and reducing code size even further.

  %\item
  %We propose a two-tier profitability analysis for the decision-making heuristic of the function merging optimisation.
  %First, we use a deep learning model responsible for filtering out pairs of input functions that are more likely to result in an unprofitable merge operation.
  %Second, we use a more accurate but expensive cost model based on a partial recompilation of the code.
  \item In order to reduce the compilation-time overheads, we propose a new sequence alignment strategy that works on the basic block level. Because basic blocks tend to be much smaller than whole functions, this strategy greatly reduces the impact of the quadratic sequence alignment algorithm.

  \item We propose a linear pairwise alignment that works on pairs of basic blocks of the same size. We have observed that profitably merged functions tend to have highly similar basic blocks.

  %\item 

\end{itemize}

\section{Structure}

This thesis is organised as follows:
\begin{description}

\item[Chapter~\ref{chp:background}] provides the main background. It provides an overview of the compiler architecture and compiler optimisations for code size reduction.
It also provides terminology and describes the sequence alignment algorithm from bioinformatics.
Finally, it describes the deep learning techniques used in this work.

\item[Chapter~\ref{chp:relatedwork}] surveys the relevant literature. First we describe the classic compiler optimisations that work by reducing code size. Second, we study the existing techniques on function merging and other techniques related to identifying code similarity. Finally, we present key papers focused on applying machine learning for tuning heuristics that guide compiler optimisations.

\item[Chapter~\ref{chp:cgo19}] describes our novel function merging technique based on sequence alignment, as well as its accompanying search strategy, where a fingerprint-based ranking mechanism is used to focus the optimisation on functions with more similarities. %Evaluation methodology

\item[Chapter~\ref{chp:pldi20}] describes our new code generator for function merging that is capable of effectively handling functions in the SSA form, optimizing phi-nodes.

\item[Chapter~\ref{chp:deeplearning}] describes our two-tier profitability analysis based on deep learning and partial recompilation. Our partial recompilation mechanism is based on {\itercomp}, where we recompile sections of code to discover profitable merging opportunities. We also propose the use of deep learning to reduce the number of recompilations needed by predicting clearly unprofitable merging attempts.

\item[Chapter~\ref{chp:conclusion}] summarises the overall findings of the thesis and outlines potential avenues for future research.

\end{description}
