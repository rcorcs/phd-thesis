
\chapter{Introduction}

In recent years, the market for mobile and embedded systems has been rapidly growing.
These systems often must run on inexpensive and resource-constrained devices, with limited memory, storage, CPU caches. and their applications are designed with different goals compared to traditional computing systems.
Applications for these systems are designed with different goals compared to traditional computing systems.

%Furthermore, the rise of the Internet of Things (IoT) depends heavily on tiny and efficient devices.
%Some of these devices can have as little as only a few kilobytes of
%memory~\cite{yelamarthi17,plaza18}.
%At the same time, low-end devices have been playing an important role in driving
%innovation in developing countries~\cite{hart02,etzo10}.

Mobile systems need to support as many devices as possible, including low-end devices with limited resources~\cite{hart02,etzo10}.
Another concern for mobile systems is the data consumption for downloads or updates of the application, which needs to be minimized as data over wireless carriers can be either limited or expensive.
As a result, there is an increasing focus on the development of programs tailored for these low-end devices with limited memory sizes~\cite{androidGo,hahm16}.

In a similar way, embedded systems are becoming increasingly complex, with their application binaries often reaching several megabytes in size, turning memory size into a limiting factor~\cite{plaza18}.
Just adding more memory is not always a viable option.
Highly integrated systems-on-chip are common in this market and their memories typically occupy the largest fraction of the chip area, contributing to most of the overall cost.
Even small increases in memory area translate directly to equivalent increases in cost, which lead to enormous levels of lost profit at large scales~\cite{edler10}.

In such constrained scenarios, reducing the application footprint is essential~\cite{schultz03,varma04,sehgal12,keoh14,auler17}.
This is traditionally achieved by focusing on reducing the code size, either when designing the source code or by tuning the compiler to optimize for size~\cite{fisher05,sehgal12,hennessy17,rocha19}.
%Unfortunately, production compilers offer little help beyond dead-code elimination or merging identical functions~\cite{tallam10,kwan12,livska14}.
%Developers might have more luck just removing functionality from their libraries~\cite{keoh14} or hand-optimizing their code~\cite{weaver09}.
%Despite the importance of keeping code size small, compilers still make little effort to reduce it, except for these classical optimisations, their efforts are limited to disabling performance optimisations which increase size.
Despite the importance of keeping code size small, production compilers offer little help beyond a few classical optimisations~\cite{cocke70,briggs97,debray00}.
Because of that, to avoid the expensive costs of extra storage and memory, the developers of these systems have to manually find ways to shrink their code, which is also costly and undesirable~\cite{keoh14,weaver09}.

Code-size optimisations work by replacing a piece of code with another that is semantically equivalent but uses fewer or smaller instructions, sometimes combining and reusing equivalent pieces of code.
Classical optimisations that are effective in reducing code size include the elimination of redundant, unreachable, and dead code, as well as certain kinds of strength reduction~\cite{cocke70,briggs97,debray00}.
Although initially motivated by performance, these classical optimisations achieve better performance by focusing on code-size reduction.

One optimisation that can potentially reduce code size is function merging.
In its simplest form, function merging reduces replicated code by combining multiple identical functions into a single one~\cite{llvm-fm,livska14}.
This optimisation is found in linkers, by the name of \textit{Identical code folding}~(ICF), where text-identical functions at the bit level are merged~\cite{tallam10,kwan12,msvc-icf}.
However, such solutions are platform-specific and need to be adapted for each object code format and hardware architecture.
Alternatively, compilers also provide a similar optimisation for merging identical functions at their mid-level intermediate representation (IR) and hence is agnostic to the target hardware~\cite{llvm-fm,livska14}.
Unfortunately, these optimisations can only merge fully identical functions with at most type mismatches that can be losslessly cast to the same format.

More advanced approaches can identify similar in functions and replace them with a single function that combines the functionality of the original functions while eliminating redundant code.
At a high level, the way this works is that code specific to only one input function is added to the merged function but made conditional to a function identifier, while code found in both input functions is added only once and executed regardless of the function identifier.
The work presented by von Koch~et~al.~\cite{edler14} proposed a merging strategy that exploits the isomorphism in the control-flow graphs (CFG) of the functions being merged.
These functions can only differ between corresponding instructions, specifically, in their opcodes or the number and types of the input operands.
However, they must have identical CFGs and function types.

%Although a simple and intuitive concept, it is crucial for making high-level abstractions usable, when they introduce duplicate code~\cite{tallam10,kwan12}.
%For example, some C++ ABIs may end up creating multiple identical constructors and destructors of a class to use in different contexts~\cite{kwan12} and C++ templates replicate code for different specialisations~\cite{tallam10,livska14}.
%More advanced approaches~\cite{edler14} have extended this idea into merging non-identical functions by leveraging structural similarity.
%Functions with identical control-flow graphs (CFGs) and only small differences within corresponding basic blocks are merged into a single function that maintains the semantics of the original functions.
%This is particularly important for handling specialized template functions with small differences in their compiled form.

%This includes optimisations that range from local to inter-procedural, such as:
%peephole optimisations that perform code simplification~\cite{tanenbaum82};
%elimination of unreachable or dead code~\cite{muchnick98};
%optimisations that reduce redundancies such as common-subexpression elimination and value numbering~\cite{cocke70,briggs97};
%procedural abstraction and function merging~\cite{loki04,edler10,rocha19}.

%Similar functions can arise for several reasons
%Generative programming~\cite{czarnecki99,draheim04}.
%Copy-and-paste programming~\cite{kim04,jablonski10,ahmed15}.

% Function merging reduces replicated code by combining multiple identical functions into a single one~\cite{llvm-fm,livska14}. 
% Although a simple and intuitive concept, it is crucial for making high-level
% abstractions usable, when they introduce duplicate code~\cite{tallam10,kwan12}.
% For example, some C++ ABIs may end up creating multiple identical constructors
% and destructors of a class to use in different contexts~\cite{kwan12} and C++
% templates replicate code for different specialisations~\cite{tallam10,livska14}.
% More advanced approaches~\cite{edler14} have extended this idea into
% merging non-identical functions by leveraging structural similarity. Functions
% with identical control-flow graphs (CFGs) and only small differences within
% corresponding basic blocks are merged into a single function that maintains
% the semantics of the original functions. This is particularly important for
% handling specialized template functions with small differences in their
% compiled form.

Unfortunately, existing approaches fail  to produce any noticeable code size reduction.
In this work, we introduce a novel way to merge functions that overcomes major limitations of existing techniques.
Our insight is that the weak results of existing function merging implementations are not due to the lack of duplicate code but due to the rigid, overly restrictive algorithms they use to find duplicates.

% While an improvement, even the state-of-the-art often usually fails to produce any
% noticeable code size reduction.
% In this paper, we introduce a novel way to merge
% functions that overcomes the major limitations of the state-of-the-art. Our
% insight is that the weak results of existing function merging implementations
% are not due to the lack of duplicate code but due to the rigid, overly restrictive
% algorithms they use to find duplicates.

\section{Contribution}

Our approach is based upon the concept of sequence alignment, developed in bioinformatics for identifying functional or evolutionary relationships between different DNA or RNA sequences.
Similarly, we use sequence alignment to find areas of functional similarity in arbitrary function pairs.
Aligned segments with equivalent code are merged.
The remaining segments where the two functions differ are added to the new function too but have their code guarded by a function identifier.
This approach leads to significant code size reduction.
%more than three times better than the state-of-the-art can achieve.

Applying sequence alignment to all pairs of functions is prohibitively expensive even for medium sized programs.
To counter this, our technique is integrated with a ranking-based exploration mechanism that efficiently focuses the search to the most
promising pairs of functions. %\todo{whats interesting about this ranking?}.
As a result, we achieve our code size savings while introducing little compilation-time
overhead.

Compared to identical function merging, we introduce extra code to be executed,
namely the code that chooses between dissimilar sequences in merged functions.
A naive implementation could easily hurt performance, e.g by merging two hot functions
with only few similarities. Our implementation can avoid this by incorporating
profiling information to identify blocks of hot code and effectively minimize 
the overhead in this portion of the code.
%disable code size optimisations for them. 

In this paper, we make the following contributions:
\begin{itemize}
  \item We are the first to allow merging arbitrary functions, even ones with
    different signatures and CFGs.
  \item A novel ranking mechanism for focusing inter-procedural optimisations
    to the most profitable function pairs.
  \item Our function merging by sequence alignment technique is able to reduce
     code size by up to 25\% on Intel and 30\% on ARM, significantly outperforming the
    state-of-the-art, while introducing minimal compile-time and negligible run-time overheads.
\end{itemize}