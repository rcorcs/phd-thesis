
\chapter{Function Merging for Free} \label{chp:lctes21}


\renewcommand{\ProjName}{{HyFM}\xspace}
\newcommand{\SOAName}{{SalSSA}\xspace}
\newcommand{\NW}{{Needleman-Wunsch}\xspace}


%The current state-of-the-art, {\SOAName}~\cite{rocha19,rocha20}, 
%The technique proposed in Chapter~\ref{chp:pldi20}, {\SOAName}, achieves on average a 10\% code size reduction but at the cost of crippling compile-time inefficiencies for large programs.
The technique proposed in Chapter~\ref{chp:pldi20}, {\SOAName}, can lead to 40\% slower compilation, taking up to 32~GB of memory for temporary data when compiling a modestly-sized program.
Such a resource requirement is beyond what is typically available to a developer and thus unsuitable for optimizing real-life programs.
%assuming the development system has that much available memory to begin with.

These inefficiencies stem directly from {\SOAName}'s core innovation, i.e., the sequence alignment algorithm used to identify mergeable instructions in a pair of input functions.
The alignment algorithm has quadratic time and space complexity, so applying it on whole functions with thousands of instructions results in unacceptable overheads.
This severely limits the applicability of function merging on relatively large programs.
%A different function merging approach that delivers similarly high code size reduction without the overheads is necessary.
To make function merging scalable and practical, we need to find ways to significantly reduce the memory and compilation overhead.
In this chapter, we offer such capabilities.   

%However, given its powerful capability for code size reduction, we need function merging techniques with acceptable compilation overheads.
%and it might even make it a bad idea for use on smaller programs.
%In either case, making it part of a standard compiler optimisation sequence is inadvisable.
%\fixme{MC: you could be stronger here, it's not like the SalSSA people are going to review it}

We present \ProjName, a novel function merging technique that addresses the performance inefficiencies of \SOAName.
Our main insight is that most of the code reduction of {\SOAName} comes from matching highly similar basic blocks.
Even though it is able to align arbitrary subsequences spanning basic block boundaries, profitable alignments usually contain instructions from one block matched to instructions from a single other block.
%The quadratic alignment algorithm, while in principle able to align subsequences spanning basic block boundaries, usually ends up aligning instructions from one block to instructions from a single other block.
We show that an approach which quickly identifies similar basic blocks and then aligns their short instruction sequences achieves a similar code reduction for a much lower overhead.

More specifically, our solution is three fold:
\begin{itemize} %[noitemsep,topsep=3pt]
   \item We align the input functions on a per basic block manner.
   % PP: The fingerprint bit is a detail that we have not discussed and the reviewer might not understand its meaning. Also are contribution regarding fingerprints is minimal.
   First, we pair similar basic blocks by minimizing the distance between their fingerprints.
   Then, we only align the instructions within each pair of basic block.  
   Even with a quadratic alignment algorithm, basic blocks are usually much shorter than functions, translating into a much faster alignment.
   \item We propose a linear pairwise alignment as an alternative to the quadratic one. For highly similar basic blocks, it achieves similar results but has negligible time and space overheads.
   \item We estimate the profitability of the aligned basic blocks before actually generating their merged code.
   If unprofitable, we ignore them, improving the overall profitability of the whole merged function and simplifying code generation.
   If all paired blocks in a pair of functions are unprofitable, we skip merging the function pair altogether, speeding up the optimisation process compared to {\SOAName}. 
\end{itemize}

Experimental results on SPEC CPU 2006 and 2017 show that {\ProjName} runs over 4.5$\times$ faster than {\SOAName}.
%reducing end-to-end compilation time by up to \fixme{18}\%.
%Such a fast function merging technique translates to a 
Compared to a baseline without function merging, {\ProjName} reduces end-to-end compilation time by up to 18\% and 2.1\% on average.
%This reduction on end-to-end compilation time is possible due to 
%In most cases the time overhead of our approach is comparable to the speedup experienced by later compilation stages due to the reduced amount of code, making applying {\ProjName} time-neutral.
{\ProjName} also has orders of magnitude lower peak memory usage, using up to 48~MB or 5.6~MB, depending on the variant used, while {\SOAName} requires 32~GB in the worst case.
We achieve all these compilation-time benefits without degrading its ability to reduce code size.


\input{src/lctes21/motivation}
\input{src/lctes21/contribution}
\input{src/lctes21/results}
\input{src/lctes21/conclusion}

