\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Overview of the three-phase compiler infrastructure.\relax }}{9}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Breakdown of the frontend, illustrating how compilers are organised as a series of phases.\relax }}{10}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Sequence of representations used during the compilation pipeline in modern compilers.\relax }}{10}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Overview of the default compilation pipeline.\relax }}{11}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Overview of the compilation pipeline using LTO.\relax }}{12}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Example of an optimum alignment between two sequences. Matching segments are shown in green, vertically centred, and the non-matching segments are shown in red at the sides.\relax }}{13}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Example of the \textit {similarity matrix} computed for two input sequences. The highlighted cells represent the resulting alignment computed by the Needleman-Wunsch algorithm.\relax }}{15}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Set of rules used to compute the scores of the similarity matrix. The two first rules represent the penalty of inserting a horizontal or vertical gap. The diagonal rule depends whether we have a matching or mismatching pair of input characters.\relax }}{16}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Example of identical functions.\relax }}{19}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Two function extracted from the \texttt {447.dealII} benchmark that are not identical at the source level, but after applying template specialisation and optimisations they become identical at the IR level.\relax }}{19}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Example of two pairs of highly similar functions. Because they are not identical, they cannot be merged by the function merging technique currently found in major compilers.\relax }}{24}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces An example of two functions with isomorphic CFGs and their corresponding basic blocks arranged side by side. Instructions in paired basic blocks are compared in a pairwise manner.\relax }}{25}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces An example of a merged basic block containing two mismatching pairs of instructions. A split is added for every pair of mismatching instructions with the phi-node instruction added to the their immediate point of convergence.\relax }}{26}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Example of two functions from the benchmark \texttt {sphinx} with different parameters that could be merged, as shown at the bottom. We highlight where they differ.\relax }}{30}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Example of two functions from the benchmark \texttt {libquantum} with different CFGs that could be merged, as shown at the bottom. We highlight where they differ.\relax }}{31}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Overview of our function-merging technique. Equivalent segments of code is represented in light green and the non-equivalent ones in dark red.\relax }}{33}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Linearizing the CFG of an example function.\relax }}{34}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces The sequence alignment between two functions.\relax }}{35}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Example of a merge operation on the parameter lists of two functions.\relax }}{37}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Overview of our exploration framework.\relax }}{40}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Average CDF for the position of the profitable candidate and the percentage of merged operations covered. 89\% of the merge operations happen with the topmost candidate.\relax }}{41}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces In our experiments we use a compilation pipeline with a monolithic link-time optimization (LTO).\relax }}{43}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Object file size reduction for Intel (top) and ARM (bottom). We evaluate our approach (FMSA) under four different exploration thresholds, which control how many potential merging pairs we examine for each function before making a decision. Even for a threshold of one, we outperform the state-of-the-art by 2.4$\times $\nobreakspace {}(Intel) and 1.9$\times $\nobreakspace {}(ARM).\relax }}{45}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces Object file size reduction for Intel on the Mibench benchmark suite. Our approach (FMSA) is the only one able to achieve a meaningful reduction on these benchmarks. \relax }}{49}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces Compilation-time overhead on the Intel platform. For exhaustive exploration (not shown) the average overhead is 25$\times $. Through ranking, we reduce overhead by orders of magnitude. For an exploration threshold of one, FMSA has an overhead of only 15\%.\relax }}{49}%
\contentsline {figure}{\numberline {4.13}{\ignorespaces A compilation-time breakdown isolating the percentage for each major step of the optimization (t=1).\relax }}{50}%
\contentsline {figure}{\numberline {4.14}{\ignorespaces Runtime overhead on the Intel platform. Performance impact is almost always statistically insignificant. For the few benchmarks affected, FMSA merges hot functions.\relax }}{50}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Original input functions to be merged, before register demotion. These simplified functions highlight a problem commonly seen in real programs.\relax }}{55}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Desired merged function that can be produced by an expert. An extra argument called \texttt {\%fid} is used to select between the two functions. This represents a gain of about 20\% in the total number of instructions.\relax }}{56}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Aligned example functions after register demotion. The functions double in size after demotion, slowing down alignment. Merging some of the generated stack accesses will prevent eliminating them later through register promotion.\relax }}{57}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Average normalized function size, before and after register demotion, across all functions in each program from the SPEC 2006 benchmark suite. Register demotion increases function size by almost 75\% on average. \relax }}{58}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces Example functions aligned without register demotion. \textit {Phi-nodes} are excluded from alignment.\relax }}{59}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces Merged CFG produced by {{SalSSA}\xspace }. Code corresponding to a single input basic block may be transformed into a chain of blocks, separating matching and non-matching code. The generator inserts conditional and unconditional branches to maintain the same order of instructions from the input basic block. Operands and edges highlighted in blue will be resolved by the operand assignment described in Section\nobreakspace {}5.2.2\hbox {}.\relax }}{60}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces Operand selection for the \texttt {call} instruction in \texttt {L\textsubscript {4}} from Figure\nobreakspace {}5.6\hbox {}. Mismatching operands chosen with a \texttt {select} instruction on the function identifier.\relax }}{62}%
\contentsline {figure}{\numberline {5.8}{\ignorespaces Optimizing operand assignment for commutative instructions. Example of a merged \texttt {add} instruction that can have its operands reordered to allow merging the two uses of \texttt {\%m}, avoiding a \textit {select} instruction.\relax }}{62}%
\contentsline {figure}{\numberline {5.9}{\ignorespaces Label selection for mismatched terminator instruction operands \texttt {L\textsubscript {f1}} and \texttt {L\textsubscript {f2}} corresponding to labels of two different basic blocks. We handle control flow in a new basic block, \texttt {L\textsubscript {sel}} with a conditional branch on the function identifier targeting the two labels. We use the label of the new block as the merged terminator operand.\relax }}{63}%
\contentsline {figure}{\numberline {5.10}{\ignorespaces Optimizing label assignment for conditional branches. Example of a merged \texttt {br} instruction that can have its label operands reordered, trading two label selections by one xor operation.\relax }}{64}%
\contentsline {figure}{\numberline {5.11}{\ignorespaces Landing blocks are added after operand assignment and are assigned to invoke instructions as operands.\relax }}{64}%
\contentsline {figure}{\numberline {5.12}{\ignorespaces Example of how {{SalSSA}\xspace } uses the standard SSA construction algorithm to guarantee the dominance property of the SSA form.\relax }}{65}%
\contentsline {figure}{\numberline {5.13}{\ignorespaces Phi-node coalescing reduces the number of phi-nodes and selections.\relax }}{66}%
\contentsline {figure}{\numberline {5.14}{\ignorespaces Reducing the number of phi-nodes by coalescing disjoint definitions with no user instructions in common.\relax }}{67}%
\contentsline {figure}{\numberline {5.15}{\ignorespaces Compilation pipeline used for the evaluation. Both SalSSA and FMSA are applied in LTO mode.\relax }}{68}%
\contentsline {figure}{\numberline {5.16}{\ignorespaces Linked object size reduction over LLVM LTO when performing function merging with {{SalSSA}\xspace } or FMSA on SPEC CPU 2006 (a) and 2007 (b). Each approach was evaluated using three different exploration thresholds. On SPEC CPU2006, {{SalSSA}\xspace } reduces code size by 9.3\% to 9.7\% on average, almost twice as much as FMSA. On SPEC CPU2017, {{SalSSA}\xspace } reduces code size by 7.9\% to 9.2\% on average, more than twice as much as FMSA.\relax }}{69}%
\contentsline {figure}{\numberline {5.17}{\ignorespaces The percentual reduction in size of the linked object files, targeting the ARM architecture. We evaluate {{SalSSA}\xspace } or FMSA over the LLVM LTO on the MiBench embedded benchmark suite. Each approach was evaluated using three different exploration thresholds. {{SalSSA}\xspace } achieves a geo-mean reduction of 1.4\% to 1.6\%, about twice as much as FMSA.\relax }}{72}%
\contentsline {figure}{\numberline {5.18}{\ignorespaces A breakdown of {{SalSSA}\xspace }[$t=1$] on the \texttt {djpeg} benchmark. The actual contribution to the final code size for each merge operation deemed profitable by the cost model.\relax }}{72}%
\contentsline {figure}{\numberline {5.19}{\ignorespaces Evaluation of the impact of phi-node coalescing on the size of the final object file. {{SalSSA}\xspace }-NoPC, which includes phi-node coalescing, has a measurable benefit over the alternative without phi-node coalescing ({{SalSSA}\xspace }-NoPC). When enabled, phi-node coalescing achieves up to 7\% of code size reduction on top of {{SalSSA}\xspace }-NoPC. \relax }}{73}%
\contentsline {figure}{\numberline {5.20}{\ignorespaces Total number of profitable merge attempts for {{SalSSA}\xspace } and FMSA on 19 SPEC CPU2006 benchmarks. For both cases, we used the lowest exploration threshold (t=1). {{SalSSA}\xspace } achieves 31\% more profitable merge operations.\relax }}{74}%
\contentsline {figure}{\numberline {5.21}{\ignorespaces Peak memory usage during compilation time on the SPEC CPU2006 benchmark. On average, {{SalSSA}\xspace } requires less than half the memory used by FMSA.\relax }}{74}%
\contentsline {figure}{\numberline {5.22}{\ignorespaces Speedup over the accumulated time spent on both sequence alignment and code generation. {{SalSSA}\xspace } produces significantly less overhead than the state-of-the-art FMSA.\relax }}{75}%
\contentsline {figure}{\numberline {5.23}{\ignorespaces End-to-end compile-time for {{SalSSA}\xspace } and FMSA for three different exploration thresholds and 19 different SPEC CPU2006 benchmark. Compile-time is normalized to that of the baseline with no function merging. {{SalSSA}\xspace } reduces the overhead of function merging by 3$\times $ to 3.7$\times $ on average.\relax }}{76}%
\contentsline {figure}{\numberline {5.24}{\ignorespaces Comparison between the runtime impact from FMSA and {{SalSSA}\xspace }. Our approach increases the runtime overhead because it merges more functions. For most benchmarks, the overhead is small. For the rest, profiling-directed merging would eliminate the overhead.\relax }}{76}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Breakdown of the relative runtime for the different stages from {{SalSSA}\xspace }. Alignment takes 25 seconds and 4.2 minutes on \texttt {638.imagick\_s} and \texttt {602.gcc\_s}, respectively.\relax }}{82}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces Example extracted from \texttt {483.xalancbmk} in SPEC CPU2006. Instructions marked green have been aligned through sequence alignment with an instruction from the other function. {{SalSSA}\xspace } would attempt merging all matched instructions but only the ones in fully aligned basic blocks would be profitable.\relax }}{83}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces Two examples of the pairwise alignment. Only instructions in corresponding positions are aligned. Instructions match if they have the same opcode.\relax }}{87}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces Example with code reordering extracted from the \texttt {450.soplex} program.\relax }}{89}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces Linked object size reduction over LLVM LTO when performing function merging with {{HyFM}\xspace } or {{SalSSA}\xspace } on SPEC CPU 2006 and 2017. On average, {{HyFM}\xspace } improves code size reduction.\relax }}{91}%
\contentsline {figure}{\numberline {6.6}{\ignorespaces Speedup of the function merging pass in isolation relative to {{SalSSA}\xspace }. The multi-tier profitability analysis reduces the number of unprofitable merge operations leading to a significant speedup.\relax }}{93}%
\contentsline {figure}{\numberline {6.7}{\ignorespaces Breakdown of the relative runtime for the different stages of the function merging pass. All measurements are normlized by {SalSSA}\xspace 's total runtime on the corresponding benchmark. For every benchmark, we show {{SalSSA}\xspace }, [PA,NMP], [PA], [NW,NMP], and [NW], in this order. \relax }}{94}%
\contentsline {figure}{\numberline {6.8}{\ignorespaces Normalized end-to-end compilation time for SPEC 2017 and SPEC 2006 relative to LLVM LTO.\relax }}{96}%
\contentsline {figure}{\numberline {6.9}{\ignorespaces Average reduction speed on both SPEC 2006 and 2017.\relax }}{97}%
\contentsline {figure}{\numberline {6.10}{\ignorespaces Peak memory usage of {{SalSSA}\xspace } and {{HyFM}\xspace } variants for SPEC 2006 and 2017 in log scale. {{SalSSA}\xspace } has a peak memory usage several orders of magnitude hundreds higher than all other approaches. The pairwise alignment variants of {{HyFM}\xspace } need on average only a seventh of the memory needed by the {{Needleman-Wunsch}\xspace } variants.\relax }}{100}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Example of how even trivial reordering is poorly handled by the existing solutions.\relax }}{104}%
